{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NO skip user train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "from conv_nets.wesad_tries.models.net_up_down_coder3_30 import (\n",
    "    NetUpDownCoder3_30 as Model,\n",
    ")\n",
    "from ds.wesad.datasets import subjects_data\n",
    "from ds.wesad.datasets_users import SubjectsDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f8c7ffe1390>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1337\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.random.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "base_path = Path(\"/home/dmo/Documents/human_func_state/human_func_state\")\n",
    "base_path = base_path.joinpath(\n",
    "    \"models_dumps\",\n",
    "    \"wesad\",\n",
    "    \"subjects_related\",\n",
    "    \"normalised\",\n",
    "    \"common\",\n",
    "    \"before_personalised\",\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_count = 50\n",
    "optim_lr = 1e-6\n",
    "betas = \"default\"  # (0.85, 0.995) # Adam only\n",
    "each_user_rate_history = True\n",
    "ds_step_size = 5\n",
    "train_batch_size = 8\n",
    "test_batch_size = 1\n",
    "device = \"cuda\"\n",
    "Optimizer = optim.ASGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "net_with_optim_name = f\"{Model.__name__}_{Optimizer.__name__}_lr_{optim_lr}\"\n",
    "base_path = base_path / net_with_optim_name"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"rr_intervals_subject_normalised\"\n",
    "ds_train = SubjectsDataset(\n",
    "    subjects_data,\n",
    "    ds_type=\"train\",\n",
    "    step=ds_step_size,\n",
    "    key=key,\n",
    ")\n",
    "ds_test = SubjectsDataset(\n",
    "    subjects_data,\n",
    "    ds_type=\"test\",\n",
    "    step=ds_step_size,\n",
    "    key=key,\n",
    ")\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    ")\n",
    "dl_test = DataLoader(\n",
    "    ds_test,\n",
    "    batch_size=test_batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net_criterion_optimizer() -> (\n",
    "    tuple[Model, nn.CrossEntropyLoss, optim.Optimizer]\n",
    "):\n",
    "    net = Model().to(device=device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.ASGD(net.parameters())\n",
    "    return net, criterion, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "writer = SummaryWriter(log_dir=base_path / \"hist\")\n",
    "dump_name = (base_path / f\"{net_with_optim_name}_last\").with_suffix(\".pkl\")\n",
    "best_name = (base_path / f\"{net_with_optim_name}_best\").with_suffix(\".pkl\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(model: Model, dl):\n",
    "    with torch.no_grad():\n",
    "        sum_ = 0\n",
    "        for i, data in enumerate(dl):\n",
    "            inputs, labels = data\n",
    "            inputs = (\n",
    "                torch.unsqueeze(inputs, 1).to(torch.float32).to(device=device)\n",
    "            )\n",
    "\n",
    "            outputs = model(inputs).cpu()\n",
    "            eq = outputs.max(1).indices == labels\n",
    "            sum_ += eq.sum()\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def save_data(path, net_state_dict, optimizer, epoch, rate, rate_subject=None):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(\n",
    "            {\n",
    "                \"net_state_dict\": net_state_dict,\n",
    "                \"current_epoch\": epoch,\n",
    "                \"rate\": rate,\n",
    "                \"rate_subject\": rate_subject,\n",
    "                \"optimizer\": optimizer.__class__.__name__,\n",
    "                \"optimizer_params\": optimizer.param_groups,\n",
    "                \"train_batch_size\": train_batch_size,\n",
    "                \"test_batch_size\": test_batch_size,\n",
    "                \"device\": device,\n",
    "            },\n",
    "            f,\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    dl,\n",
    "    epoch,\n",
    "    min_loss,\n",
    "    out_f,\n",
    "    print_step=50,\n",
    "):\n",
    "    epoch_loss = 0.0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(dl):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = torch.unsqueeze(inputs, 1).to(torch.float32).to(device=device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs.cpu(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % print_step == print_step - 1:\n",
    "            mean_loss = running_loss / print_step\n",
    "            if mean_loss < min_loss[0]:\n",
    "                min_loss = (mean_loss, (epoch, i))\n",
    "            print(f\"[{epoch:3d}, {i:4d}] loss: {mean_loss:.3f}\", file=out_f)\n",
    "            epoch_loss += running_loss\n",
    "            running_loss = 0.0\n",
    "    epoch_loss += running_loss\n",
    "    return epoch_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    out_f,\n",
    "    epoch_count=50,\n",
    "    print_step=50,\n",
    "    start_epoch=0,\n",
    "):\n",
    "    min_loss = (torch.tensor(np.inf), 0)\n",
    "    best_common_rate = (torch.tensor(0.0), 0)\n",
    "    worst_common_rate = (torch.tensor(1.0), 0)\n",
    "    best_single_rate = (torch.tensor(0.0), 0)\n",
    "    worst_single_rate = (torch.tensor(1.0), 0)\n",
    "    model, criterion, optimizer = get_net_criterion_optimizer()\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in trange(start_epoch, epoch_count):\n",
    "        model.train()\n",
    "        epoch_loss = train_epoch(\n",
    "            model,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            dl_train,\n",
    "            epoch,\n",
    "            min_loss,\n",
    "            out_f,\n",
    "            print_step,\n",
    "        )\n",
    "        model.eval()\n",
    "        common_acc = val(model, dl_test)\n",
    "        writer.add_scalar(\"Loss/train\", epoch_loss, epoch)\n",
    "        writer.add_scalar(\"Accuracy/train\", common_acc, epoch)\n",
    "        if common_acc > best_common_rate[0]:\n",
    "            best_common_rate = (common_acc, epoch)\n",
    "            save_data(\n",
    "                best_name, model.state_dict(), optimizer, epoch, common_acc\n",
    "            )\n",
    "        if common_acc < worst_common_rate[0]:\n",
    "            worst_common_rate = (common_acc, epoch)\n",
    "        save_data(dump_name, model.state_dict(), optimizer, epoch, common_acc)\n",
    "\n",
    "        print(\n",
    "            (\n",
    "                f\"[{epoch:3d}] rate: {common_acc:.4f}; \"\n",
    "                f\"{best_common_rate = }, {worst_common_rate = }\"\n",
    "            ),\n",
    "            file=out_f,\n",
    "        )\n",
    "    return (\n",
    "        worst_common_rate,\n",
    "        best_common_rate,\n",
    "        min_loss,\n",
    "        worst_single_rate,\n",
    "        best_single_rate,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55d5ea2ef6384da9b42624faa3cb65d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(base_path / \"train.log\", \"w\") as out_f:\n",
    "    train(out_f, epoch_count=epoch_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
