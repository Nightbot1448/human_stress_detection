{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "with filtering:\n",
    "driver = 5\n",
    "seed = 1337\n",
    "epoch = 50\n",
    "adam lr = 0.00005\n",
    "worst rate: 0.7188 (epoch 2)\n",
    "best rate: 0.9688 (epoch 25)\n",
    "loss: 0.2239 (epoch: 27) -- 0.22391266226768494\n",
    "\n",
    "\n",
    "((tensor(0.7188), 2), (tensor(0.9688), 25), (0.22391266226768494, 27))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from ds.drivers.datasets import DriverDataset, DriversDataset, all_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f116af21bb0>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 1337\n",
    "np.random.seed(seed)\n",
    "torch.random.manual_seed(seed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "base_path = \"/home/dmo/Documents/human_func_state\"\n",
    "models_dumps = os.path.join(base_path, \"models_dumps\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "epoch_count = 200\n",
    "adam_lr = 0.0001\n",
    "train_batch_size = 8\n",
    "test_batch_size = 1\n",
    "ds_step_size = 5\n",
    "device = \"cuda\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class ConvX(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_planes, out_planes, kernel=3, stride=1, padding=None\n",
    "    ):\n",
    "        super(ConvX, self).__init__()\n",
    "        padding = kernel // 2 if padding is None else padding\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_planes,\n",
    "            out_planes,\n",
    "            kernel_size=kernel,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(out_planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.bn(self.conv(x)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Net6Conv2MaxPool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net6Conv2MaxPool, self).__init__()\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            ConvX(1, 1, kernel=2, padding=0),\n",
    "            ConvX(1, 1, kernel=2, padding=0),\n",
    "            nn.MaxPool1d(2),\n",
    "            ConvX(1, 1, kernel=2, padding=0),\n",
    "            ConvX(1, 1, kernel=2, padding=0),\n",
    "            nn.MaxPool1d(2),\n",
    "            ConvX(1, 1, kernel=2, padding=0),\n",
    "            ConvX(1, 1, kernel=2, stride=2),\n",
    "            nn.Conv1d(1, 1, kernel_size=2),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(torch.flatten(self.seq(x), 1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(0.8159)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\n",
    "    os.path.join(\n",
    "        models_dumps, \"Net6Conv2MaxPool_ASGD_lr_0.0001_betas_default.pkl\"\n",
    "    ),\n",
    "    \"rb\",\n",
    ") as f:\n",
    "    data = pickle.load(f)\n",
    "data.get(\"rate\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def get_net_and_optimizer():\n",
    "    net = Net6Conv2MaxPool()\n",
    "    net.load_state_dict(data.get(\"net_state_dict\"))\n",
    "    children = list(net.seq.children())\n",
    "    for i, child in enumerate(children):\n",
    "        if i != len(children) - 1:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = False\n",
    "    net = net.to(device=device)\n",
    "    optimizer = optim.Adam(net.seq[-1].parameters(), lr=adam_lr)\n",
    "    return net, optimizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def noop(*_args, **_kwargs):\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def val(model, dl_test, return_valid_count_only=True):\n",
    "    labels_ = []\n",
    "    outputs_ = []\n",
    "    with torch.no_grad():\n",
    "        sum_ = 0\n",
    "        for i, data in enumerate(dl_test):\n",
    "            inputs, labels = data\n",
    "            labels_.append(labels)\n",
    "            inputs = (\n",
    "                torch.unsqueeze(inputs, 1).to(torch.float32).to(device=device)\n",
    "            )\n",
    "            outputs = model(inputs).cpu()\n",
    "            outputs = outputs.max(1).indices\n",
    "            outputs_.append(outputs)\n",
    "            eq = outputs == labels\n",
    "            sum_ += eq.sum()\n",
    "\n",
    "    return sum_ if return_valid_count_only else (sum_, labels_, outputs_)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    dl_train,\n",
    "    dl_test,\n",
    "    epoch_count=50,\n",
    "    print_step=50,\n",
    "    print_f=noop,\n",
    "):\n",
    "    min_loss = (np.inf, 0)\n",
    "    best_rate = (0, 0)\n",
    "    worst_rate = (1.0, 0)\n",
    "    len_test = len(dl_test) * dl_test.batch_size\n",
    "    for epoch in range(epoch_count):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        model.train()\n",
    "        for i, data in enumerate(dl_train):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs = (\n",
    "                torch.unsqueeze(inputs, 1).to(torch.float32).to(device=device)\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs.cpu(), labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "        mean_loss = running_loss / print_step\n",
    "        if mean_loss < min_loss[0]:\n",
    "            min_loss = (mean_loss, epoch)\n",
    "        count_of_correct = val(model, dl_test)\n",
    "        rate = count_of_correct / len_test\n",
    "        if rate > best_rate[0]:\n",
    "            best_rate = (rate, epoch)\n",
    "        if rate < worst_rate[0]:\n",
    "            worst_rate = (rate, epoch)\n",
    "\n",
    "        print_f(\n",
    "            f\"[{epoch + 1}] \"\n",
    "            f\"rate: {rate:.4f} - {count_of_correct:3d}/{len_test}; \"\n",
    "            f\"{best_rate = }, {worst_rate = }, loss: {mean_loss:.3f}\"\n",
    "        )\n",
    "    return worst_rate, best_rate, min_loss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "ds_all_test = DriversDataset(\n",
    "    all_data,\n",
    "    ds_type=\"test\",\n",
    "    data_field=\"working_data_filtered\",\n",
    "    step=ds_step_size,\n",
    ")\n",
    "dl_all_test = DataLoader(\n",
    "    ds_all_test,\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    "    num_workers=1,\n",
    "    pin_memory=False,\n",
    "    drop_last=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All\n",
      "Rate:  tensor(0.8159)\n"
     ]
    }
   ],
   "source": [
    "net, optimizer = get_net_and_optimizer()\n",
    "net.eval()\n",
    "print(\"All\")\n",
    "acc = val(net, dl_all_test)\n",
    "print(\"Rate: \", acc / len(ds_all_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "drivers_test_datasets = {\n",
    "    driver_id: DriverDataset(\n",
    "        driver_data,\n",
    "        ds_type=\"test\",\n",
    "        data_field=\"working_data_filtered\",\n",
    "        step=ds_step_size,\n",
    "    )\n",
    "    for driver_id, driver_data in all_data.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Driver 5\n",
      "rate before:  tensor(0.8155)\n",
      "-------------------------\n",
      "Driver 6\n",
      "rate before:  tensor(0.)\n",
      "-------------------------\n",
      "Driver 7\n",
      "rate before:  tensor(0.3175)\n",
      "-------------------------\n",
      "Driver 8\n",
      "rate before:  tensor(1.)\n",
      "-------------------------\n",
      "Driver 9\n",
      "rate before:  tensor(0.9756)\n",
      "-------------------------\n",
      "Driver 10\n",
      "rate before:  tensor(1.)\n",
      "-------------------------\n",
      "Driver 11\n",
      "rate before:  tensor(0.9588)\n",
      "-------------------------\n",
      "Driver 12\n",
      "rate before:  tensor(0.9296)\n",
      "-------------------------\n",
      "Driver 15\n",
      "rate before:  tensor(0.9189)\n",
      "-------------------------\n",
      "Driver 16\n",
      "rate before:  tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "for driver_id, ds_test in drivers_test_datasets.items():\n",
    "    # ds_train = DriverDataset(driver_data, ds_type=\"train\", data_field=\"working_data_filtered\")\n",
    "    # ds_test = DriverDataset(driver_data, ds_type=\"test\", data_field=\"working_data_filtered\", step=ds_step_size)\n",
    "\n",
    "    # dl_train = DataLoader(\n",
    "    #     ds_train,\n",
    "    #     batch_size = train_batch_size,\n",
    "    #     shuffle = True,\n",
    "    #     num_workers = 1,\n",
    "    #     pin_memory = False,\n",
    "    #     drop_last = True\n",
    "    # )\n",
    "    dl_test = DataLoader(\n",
    "        ds_test,\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=1,\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    print(\"-------------------------\")\n",
    "    net, optimizer = get_net_and_optimizer()\n",
    "    net.eval()\n",
    "    print(\"Driver\", driver_id)\n",
    "    acc = val(net, dl_test)\n",
    "    accs.append(acc / len(ds_test))\n",
    "    print(\"rate before: \", accs[-1])\n",
    "    # worst, best, loss = train(net, optimizer, dl_train, dl_test, epoch_count=epoch_count)\n",
    "    # print(f\"{best = }, {worst = }, {loss = }\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor(0.8155),\n tensor(0.),\n tensor(0.3175),\n tensor(1.),\n tensor(0.9756),\n tensor(1.),\n tensor(0.9588),\n tensor(0.9296),\n tensor(0.9189),\n tensor(1.)]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# driver_id = 6\n",
    "# driver_data = all_data.get(driver_id)\n",
    "# ds_train = DriverDataset(driver_data, ds_type=\"train\", data_field=\"working_data_filtered\")\n",
    "# ds_test = DriverDataset(driver_data, ds_type=\"test\", data_field=\"working_data_filtered\")\n",
    "#\n",
    "# dl_train = DataLoader(\n",
    "#     ds_train,\n",
    "#     batch_size = train_batch_size,\n",
    "#     shuffle = True,\n",
    "#     num_workers = 1,\n",
    "#     pin_memory = False,\n",
    "#     drop_last = True\n",
    "# )\n",
    "# dl_test = DataLoader(\n",
    "#     ds_test,\n",
    "#     batch_size = test_batch_size,\n",
    "#     shuffle = True,\n",
    "#     num_workers = 1,\n",
    "#     pin_memory = False,\n",
    "#     drop_last = True\n",
    "# )\n",
    "# print(\"-------------------------\")\n",
    "# net, optimizer = get_net_and_optimizer()\n",
    "# print(\"Driver\", driver_id)\n",
    "# print(\"rate before: \", val(net, dl_test) / len(ds_test))\n",
    "# worst, best, loss = train(net, optimizer, dl_train, dl_test, epoch_count=epoch_count)\n",
    "# print(f\"{best = }, {worst = }, {loss = }\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(7.9159)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(accs)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, tensor(0.8155))\n",
      "(6, tensor(0.))\n",
      "(7, tensor(0.3175))\n",
      "(8, tensor(1.))\n",
      "(9, tensor(0.9756))\n",
      "(10, tensor(1.))\n",
      "(11, tensor(0.9588))\n",
      "(12, tensor(0.9296))\n",
      "(15, tensor(0.9189))\n",
      "(16, tensor(1.))\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(map(str, zip(drivers_test_datasets.keys(), accs))))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "945"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_all_test.__len__()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 103)\n",
      "(6, 92)\n",
      "(7, 63)\n",
      "(8, 132)\n",
      "(9, 82)\n",
      "(10, 137)\n",
      "(11, 97)\n",
      "(12, 71)\n",
      "(15, 111)\n",
      "(16, 57)\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"\\n\".join(\n",
    "        map(\n",
    "            str,\n",
    "            zip(\n",
    "                drivers_test_datasets.keys(),\n",
    "                map(len, drivers_test_datasets.values()),\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
